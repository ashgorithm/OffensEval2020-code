{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Eng Task A - Ensemble DistilGPT2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f533325742ee439f82d76759601e356b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7e532fc04c54e908d7b41515b6afb2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f52138325ef40bc9fac416f7ef6d0d9",
              "IPY_MODEL_560f0a54a4ea45478d9d1ca4cb1913df"
            ]
          }
        },
        "d7e532fc04c54e908d7b41515b6afb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f52138325ef40bc9fac416f7ef6d0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aa1db5679574fc6a5d9fa2fc5ad598b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d49d1c01c55040638c3c7f366112e53a"
          }
        },
        "560f0a54a4ea45478d9d1ca4cb1913df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07976c96504b4bbaa5ec94507c802d42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 849kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_276186fd61a74c0ba0bf19acd8a35853"
          }
        },
        "2aa1db5679574fc6a5d9fa2fc5ad598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d49d1c01c55040638c3c7f366112e53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07976c96504b4bbaa5ec94507c802d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "276186fd61a74c0ba0bf19acd8a35853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e53386b0787747909e88880b2ce6ce66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b63ee51c9e834a5da6a29d36cf0fca25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b81cb6c0f514536830dd6c71fbf4a6e",
              "IPY_MODEL_b6524ac1b64040428594f8ed6e7af963"
            ]
          }
        },
        "b63ee51c9e834a5da6a29d36cf0fca25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b81cb6c0f514536830dd6c71fbf4a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e6bd4cb2f51465eb7c5865499e78a24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_780fb3de7b4743c58c58a6ecd8838d07"
          }
        },
        "b6524ac1b64040428594f8ed6e7af963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f35652ef578448b8beb232f0bb96256b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86d49be9ca694186b3f775a371ed100c"
          }
        },
        "5e6bd4cb2f51465eb7c5865499e78a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "780fb3de7b4743c58c58a6ecd8838d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f35652ef578448b8beb232f0bb96256b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86d49be9ca694186b3f775a371ed100c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c36900265d1e48d2b55533b7925ed181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_491bd6da924c4b83a20c69791ecccf9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21e6171efeac4f47a7d0d55b371f369e",
              "IPY_MODEL_9d0c545167ad49ad9e924607062fc107"
            ]
          }
        },
        "491bd6da924c4b83a20c69791ecccf9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21e6171efeac4f47a7d0d55b371f369e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5902425515e84a4c8ee061f370c3cbf0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 651,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 651,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07e317fcd8b0402a9d457eaa1f904e0e"
          }
        },
        "9d0c545167ad49ad9e924607062fc107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99538b23a3a8406e83a26648441c5df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 651/651 [00:00&lt;00:00, 22.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e3569d57a8445dd8403e5ffb694a607"
          }
        },
        "5902425515e84a4c8ee061f370c3cbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07e317fcd8b0402a9d457eaa1f904e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99538b23a3a8406e83a26648441c5df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e3569d57a8445dd8403e5ffb694a607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80a2b725f56e43cda97d34c78caf291c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0dd9f8a227d44acf8094aebcbed274ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1640898470b4a4096977d7aa1443c9f",
              "IPY_MODEL_d747855572f745749eb9509faaf844fd"
            ]
          }
        },
        "0dd9f8a227d44acf8094aebcbed274ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1640898470b4a4096977d7aa1443c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e88ca84c65b9496d940fe679899507b5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 352833716,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 352833716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60741d631e784394b1b5a0f9d4959325"
          }
        },
        "d747855572f745749eb9509faaf844fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_115c0887e5b744f4ba77808ab646baf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 353M/353M [00:06&lt;00:00, 56.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42c3babaf5d94a4db582e2f860d54300"
          }
        },
        "e88ca84c65b9496d940fe679899507b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60741d631e784394b1b5a0f9d4959325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "115c0887e5b744f4ba77808ab646baf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42c3babaf5d94a4db582e2f860d54300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaHXdQweG2gY",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cozek/OffensEval2020-code/blob/master/notebooks/Eng%20Task%20A%20-%20Ensemble%20DistilGPT2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnXQrkMlG2ga",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UcEUgF4G2gc",
        "colab_type": "text"
      },
      "source": [
        "At the time of our work, we used the following library versions\n",
        "- numpy 1.18.1\n",
        "- pandas 1.0.1\n",
        "- torch 1.2.0\n",
        "- Cuda 10.0\n",
        "- python 3.7.0\n",
        "- sklearn 0.22.1\n",
        "- tqdm 4.42.1\n",
        "- nltk 3.4.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jknbt-9FG9sq",
        "colab_type": "code",
        "outputId": "3e64a5d7-bef6-4c6f-bc41-7a2e2be3c1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "!git clone https://github.com/cozek/OffensEval2020-code/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OffensEval2020-code'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/52)\u001b[K\rremote: Counting objects:   3% (2/52)\u001b[K\rremote: Counting objects:   5% (3/52)\u001b[K\rremote: Counting objects:   7% (4/52)\u001b[K\rremote: Counting objects:   9% (5/52)\u001b[K\rremote: Counting objects:  11% (6/52)\u001b[K\rremote: Counting objects:  13% (7/52)\u001b[K\rremote: Counting objects:  15% (8/52)\u001b[K\rremote: Counting objects:  17% (9/52)\u001b[K\rremote: Counting objects:  19% (10/52)\u001b[K\rremote: Counting objects:  21% (11/52)\u001b[K\rremote: Counting objects:  23% (12/52)\u001b[K\rremote: Counting objects:  25% (13/52)\u001b[K\rremote: Counting objects:  26% (14/52)\u001b[K\rremote: Counting objects:  28% (15/52)\u001b[K\rremote: Counting objects:  30% (16/52)\u001b[K\rremote: Counting objects:  32% (17/52)\u001b[K\rremote: Counting objects:  34% (18/52)\u001b[K\rremote: Counting objects:  36% (19/52)\u001b[K\rremote: Counting objects:  38% (20/52)\u001b[K\rremote: Counting objects:  40% (21/52)\u001b[K\rremote: Counting objects:  42% (22/52)\u001b[K\rremote: Counting objects:  44% (23/52)\u001b[K\rremote: Counting objects:  46% (24/52)\u001b[K\rremote: Counting objects:  48% (25/52)\u001b[K\rremote: Counting objects:  50% (26/52)\u001b[K\rremote: Counting objects:  51% (27/52)\u001b[K\rremote: Counting objects:  53% (28/52)\u001b[K\rremote: Counting objects:  55% (29/52)\u001b[K\rremote: Counting objects:  57% (30/52)\u001b[K\rremote: Counting objects:  59% (31/52)\u001b[K\rremote: Counting objects:  61% (32/52)\u001b[K\rremote: Counting objects:  63% (33/52)\u001b[K\rremote: Counting objects:  65% (34/52)\u001b[K\rremote: Counting objects:  67% (35/52)\u001b[K\rremote: Counting objects:  69% (36/52)\u001b[K\rremote: Counting objects:  71% (37/52)\u001b[K\rremote: Counting objects:  73% (38/52)\u001b[K\rremote: Counting objects:  75% (39/52)\u001b[K\rremote: Counting objects:  76% (40/52)\u001b[K\rremote: Counting objects:  78% (41/52)\u001b[K\rremote: Counting objects:  80% (42/52)\u001b[K\rremote: Counting objects:  82% (43/52)\u001b[K\rremote: Counting objects:  84% (44/52)\u001b[K\rremote: Counting objects:  86% (45/52)\u001b[K\rremote: Counting objects:  88% (46/52)\u001b[K\rremote: Counting objects:  90% (47/52)\u001b[K\rremote: Counting objects:  92% (48/52)\u001b[K\rremote: Counting objects:  94% (49/52)\u001b[K\rremote: Counting objects:  96% (50/52)\u001b[K\rremote: Counting objects:  98% (51/52)\u001b[K\rremote: Counting objects: 100% (52/52)\u001b[K\rremote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 52 (delta 13), reused 38 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt7C7pQyHPLp",
        "colab_type": "code",
        "outputId": "ab4fe290-b302-46bf-8735-fc623a88602f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install /content/transformers/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/39)\u001b[K\rremote: Counting objects:   5% (2/39)\u001b[K\rremote: Counting objects:   7% (3/39)\u001b[K\rremote: Counting objects:  10% (4/39)\u001b[K\rremote: Counting objects:  12% (5/39)\u001b[K\rremote: Counting objects:  15% (6/39)\u001b[K\rremote: Counting objects:  17% (7/39)\u001b[K\rremote: Counting objects:  20% (8/39)\u001b[K\rremote: Counting objects:  23% (9/39)\u001b[K\rremote: Counting objects:  25% (10/39)\u001b[K\rremote: Counting objects:  28% (11/39)\u001b[K\rremote: Counting objects:  30% (12/39)\u001b[K\rremote: Counting objects:  33% (13/39)\u001b[K\rremote: Counting objects:  35% (14/39)\u001b[K\rremote: Counting objects:  38% (15/39)\u001b[K\rremote: Counting objects:  41% (16/39)\u001b[K\rremote: Counting objects:  43% (17/39)\u001b[K\rremote: Counting objects:  46% (18/39)\u001b[K\rremote: Counting objects:  48% (19/39)\u001b[K\rremote: Counting objects:  51% (20/39)\u001b[K\rremote: Counting objects:  53% (21/39)\u001b[K\rremote: Counting objects:  56% (22/39)\u001b[K\rremote: Counting objects:  58% (23/39)\u001b[K\rremote: Counting objects:  61% (24/39)\u001b[K\rremote: Counting objects:  64% (25/39)\u001b[K\rremote: Counting objects:  66% (26/39)\u001b[K\rremote: Counting objects:  69% (27/39)\u001b[K\rremote: Counting objects:  71% (28/39)\u001b[K\rremote: Counting objects:  74% (29/39)\u001b[K\rremote: Counting objects:  76% (30/39)\u001b[K\rremote: Counting objects:  79% (31/39)\u001b[K\rremote: Counting objects:  82% (32/39)\u001b[K\rremote: Counting objects:  84% (33/39)\u001b[K\rremote: Counting objects:  87% (34/39)\u001b[K\rremote: Counting objects:  89% (35/39)\u001b[K\rremote: Counting objects:  92% (36/39)\u001b[K\rremote: Counting objects:  94% (37/39)\u001b[K\rremote: Counting objects:  97% (38/39)\u001b[K\rremote: Counting objects: 100% (39/39)\u001b[K\rremote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/29)\u001b[K\rremote: Compressing objects:   6% (2/29)\u001b[K\rremote: Compressing objects:  10% (3/29)\u001b[K\rremote: Compressing objects:  13% (4/29)\u001b[K\rremote: Compressing objects:  17% (5/29)\u001b[K\rremote: Compressing objects:  20% (6/29)\u001b[K\rremote: Compressing objects:  24% (7/29)\u001b[K\rremote: Compressing objects:  27% (8/29)\u001b[K\rremote: Compressing objects:  31% (9/29)\u001b[K\rremote: Compressing objects:  34% (10/29)\u001b[K\rremote: Compressing objects:  37% (11/29)\u001b[K\rremote: Compressing objects:  41% (12/29)\u001b[K\rremote: Compressing objects:  44% (13/29)\u001b[K\rremote: Compressing objects:  48% (14/29)\u001b[K\rremote: Compressing objects:  51% (15/29)\u001b[K\rremote: Compressing objects:  55% (16/29)\u001b[K\rremote: Compressing objects:  58% (17/29)\u001b[K\rremote: Compressing objects:  62% (18/29)\u001b[K\rremote: Compressing objects:  65% (19/29)\u001b[K\rremote: Compressing objects:  68% (20/29)\u001b[K\rremote: Compressing objects:  72% (21/29)\u001b[K\rremote: Compressing objects:  75% (22/29)\u001b[K\rremote: Compressing objects:  79% (23/29)\u001b[K\rremote: Compressing objects:  82% (24/29)\u001b[K\rremote: Compressing objects:  86% (25/29)\u001b[K\rremote: Compressing objects:  89% (26/29)\u001b[K\rremote: Compressing objects:  93% (27/29)\u001b[K\rremote: Compressing objects:  96% (28/29)\u001b[K\rremote: Compressing objects: 100% (29/29)\u001b[K\rremote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "Receiving objects:   0% (1/26210)   \rReceiving objects:   1% (263/26210)   \rReceiving objects:   2% (525/26210)   \rReceiving objects:   3% (787/26210)   \rReceiving objects:   4% (1049/26210)   \rReceiving objects:   5% (1311/26210)   \rReceiving objects:   6% (1573/26210)   \rReceiving objects:   7% (1835/26210)   \rReceiving objects:   8% (2097/26210)   \rReceiving objects:   9% (2359/26210)   \rReceiving objects:  10% (2621/26210)   \rReceiving objects:  11% (2884/26210)   \rReceiving objects:  12% (3146/26210)   \rReceiving objects:  13% (3408/26210)   \rReceiving objects:  14% (3670/26210)   \rReceiving objects:  15% (3932/26210)   \rReceiving objects:  16% (4194/26210)   \rReceiving objects:  17% (4456/26210)   \rReceiving objects:  18% (4718/26210)   \rReceiving objects:  19% (4980/26210)   \rReceiving objects:  20% (5242/26210)   \rReceiving objects:  21% (5505/26210)   \rReceiving objects:  22% (5767/26210)   \rReceiving objects:  23% (6029/26210)   \rReceiving objects:  24% (6291/26210)   \rReceiving objects:  25% (6553/26210)   \rReceiving objects:  26% (6815/26210)   \rReceiving objects:  27% (7077/26210)   \rReceiving objects:  28% (7339/26210)   \rReceiving objects:  29% (7601/26210)   \rReceiving objects:  30% (7863/26210)   \rReceiving objects:  31% (8126/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  32% (8388/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  33% (8650/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  34% (8912/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  35% (9174/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  36% (9436/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  37% (9698/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  38% (9960/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  39% (10222/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  40% (10484/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  41% (10747/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  42% (11009/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  43% (11271/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  44% (11533/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  45% (11795/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  46% (12057/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  47% (12319/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  48% (12581/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  49% (12843/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  50% (13105/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  51% (13368/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  52% (13630/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  53% (13892/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  54% (14154/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  55% (14416/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  56% (14678/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  57% (14940/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  58% (15202/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  59% (15464/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  60% (15726/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  61% (15989/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  62% (16251/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  63% (16513/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  64% (16775/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  65% (17037/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  66% (17299/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  67% (17561/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  68% (17823/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  69% (18085/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  70% (18347/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  71% (18610/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  72% (18872/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  73% (19134/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  74% (19396/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  75% (19658/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  76% (19920/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  77% (20182/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  78% (20444/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  79% (20706/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  80% (20968/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  81% (21231/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  82% (21493/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  83% (21755/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  84% (22017/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  85% (22279/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  86% (22541/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  87% (22803/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  88% (23065/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  89% (23327/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  90% (23589/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  91% (23852/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  92% (24114/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  93% (24376/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  94% (24638/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  95% (24900/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  96% (25162/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  97% (25424/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  98% (25686/26210), 6.85 MiB | 13.69 MiB/s   \rReceiving objects:  99% (25948/26210), 6.85 MiB | 13.69 MiB/s   \rremote: Total 26210 (delta 15), reused 14 (delta 6), pack-reused 26171\u001b[K\n",
            "Receiving objects: 100% (26210/26210), 15.38 MiB | 19.49 MiB/s, done.\n",
            "Resolving deltas: 100% (18307/18307), done.\n",
            "Processing ./transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.3)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.8.0-cp36-none-any.whl size=595751 sha256=503a4a68f8a9cb10dba4b4e2f8774473e191d0c079d6c9ef30d1bcadd167fc8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lxv2srl8/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=584f1480118f06c5fdcbe035d0ce146a3b0afd9f9cdddbebfec859373604d730\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmMKCJ-dG2ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/OffensEval2020-code/src/')\n",
        "import collections\n",
        "from typing import Callable\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "from tqdm import notebook\n",
        "import importlib\n",
        "import pprint\n",
        "import nltk\n",
        "import datetime\n",
        "import os\n",
        "from argparse import Namespace\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWwTBxXqG2gh",
        "colab_type": "code",
        "outputId": "c47b98f5-ca00-4cda-bdac-a8bc34e40254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import utils.general as general_utils\n",
        "import utils.trac2020 as trac_utils\n",
        "import utils.transformer.data as transformer_data_utils\n",
        "import utils.transformer.general as transformer_general_utils\n",
        "general_utils.set_seed_everywhere() #set the seed for reproducibility"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EfdINgcG2gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6k1nQ5d4G2gn",
        "colab_type": "code",
        "outputId": "504f0ba2-9619-48eb-928a-dc831b09c16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcFCAJAQG2gr",
        "colab_type": "text"
      },
      "source": [
        "## Import Optimzer and XLM Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc66UeiyG2gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import RAdam and Lookahead\n",
        "from radam.radam import RAdam\n",
        "from lookahead.optimizer import Lookahead"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "sF7KP8tzG2gv",
        "colab_type": "code",
        "outputId": "3d888fea-856a-4f07-de30-b262a78ac1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:PyTorch version 1.5.0+cu101 available.\n",
            "INFO:transformers.file_utils:TensorFlow version 2.2.0-rc3 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIAYRiqhG2gz",
        "colab_type": "text"
      },
      "source": [
        "# Set up the argspace/important_variables\n",
        "Please note that performance is suseptible to hyper parameters. We used a Nvidia Tesla V100 32GB. If you lower the batch size or change any other parameters, modules to fit your machine, you might not get the same performance as reported in our paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F6tx_VrG2gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Namespace(\n",
        "        #use cuda by default\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \n",
        "        #set batch size and number of epochs\n",
        "        batch_size = 32,\n",
        "        num_epochs = 20,\n",
        "    \n",
        "        #set the learning rate\n",
        "        learning_rate = 0.0001,\n",
        "\n",
        "        #location of the train, dev and test csv\n",
        "        train_val_csv = '/content/OffensEval2020-code/data/eng/task_a_tiny.csv',\n",
        "        test_csv = '/content/OffensEval2020-code/data/test_data/test_a_tweets.tsv',\n",
        "    \n",
        "        #directory to save our models at\n",
        "        directory = './', \n",
        "        model_name = 'distilGPT2.pt',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY29sw-7G2g2",
        "colab_type": "text"
      },
      "source": [
        "## Loading a presplit subset of the full dataset data into DataFrames. \n",
        "Here, 0 : NOT, 1 : HOF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKKJ-JmZG2g3",
        "colab_type": "code",
        "outputId": "d673a783-673e-4d8a-9319-c15993b79773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "data_df =  pd.read_csv(args.train_val_csv)\n",
        "data_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1159552003770650625</td>\n",
              "      <td>@USER dancing is a talent show it offffff like...</td>\n",
              "      <td>0.321070</td>\n",
              "      <td>0.235700</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1159542583410024449</td>\n",
              "      <td>Cooking Tweeps!  I am desirous of a new ridged...</td>\n",
              "      <td>0.153384</td>\n",
              "      <td>0.168776</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1159576849976107009</td>\n",
              "      <td>@USER I can respect that I’ll see I kind of li...</td>\n",
              "      <td>0.161124</td>\n",
              "      <td>0.200444</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1159661814160011264</td>\n",
              "      <td>That song used to bring tears to my eyes in 5t...</td>\n",
              "      <td>0.316731</td>\n",
              "      <td>0.168065</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1159620953686495233</td>\n",
              "      <td>Nah.  Ranked. 1. Abortion 2. Guns 3.  Religiou...</td>\n",
              "      <td>0.428485</td>\n",
              "      <td>0.064754</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90885</th>\n",
              "      <td>1159536832469774340</td>\n",
              "      <td>This bitch wants people to die in a Mass Murder!</td>\n",
              "      <td>0.860484</td>\n",
              "      <td>0.172114</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90886</th>\n",
              "      <td>1159571431115698176</td>\n",
              "      <td>rly feel like the ugliest girl in the world im...</td>\n",
              "      <td>0.593529</td>\n",
              "      <td>0.200248</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90887</th>\n",
              "      <td>1159547322545725440</td>\n",
              "      <td>@USER I have the ss and was defending her cuz ...</td>\n",
              "      <td>0.790050</td>\n",
              "      <td>0.136956</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90888</th>\n",
              "      <td>1159662323260362752</td>\n",
              "      <td>I THOUGHT SHE WAS PREGNANT BUT THAT WAS HER AS...</td>\n",
              "      <td>0.696626</td>\n",
              "      <td>0.235508</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90889</th>\n",
              "      <td>1159539567361347584</td>\n",
              "      <td>@USER Who the hell are you?Have you forgotten ...</td>\n",
              "      <td>0.828747</td>\n",
              "      <td>0.169144</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90890 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id  ...  split\n",
              "0      1159552003770650625  ...  train\n",
              "1      1159542583410024449  ...  train\n",
              "2      1159576849976107009  ...  train\n",
              "3      1159661814160011264  ...  train\n",
              "4      1159620953686495233  ...  train\n",
              "...                    ...  ...    ...\n",
              "90885  1159536832469774340  ...   test\n",
              "90886  1159571431115698176  ...   test\n",
              "90887  1159547322545725440  ...   test\n",
              "90888  1159662323260362752  ...   test\n",
              "90889  1159539567361347584  ...   test\n",
              "\n",
              "[90890 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ZZu7WmKCxK",
        "colab_type": "code",
        "outputId": "0ae798d2-6a37-4a7e-fbf2-d5bd4967da61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "#0 = NOT, 1 = HOF\n",
        "data_df.label.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    76402\n",
              "1    14488\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCdT3E0zKdPy",
        "colab_type": "code",
        "outputId": "240cf055-0c66-41e8-d514-d2b48900012e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "with pd.option_context('display.max_colwidth', -1): \n",
        "    print(data_df[['text','label']].sample(5))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                           text  label\n",
            "31725  @USER BRO I WENT TODAY AND LITERALLY RAN INTO HOT TOPIC TO FIND UR SHIRT ANd i LITERALLY ALMOST CRIED I WANTED IT SO BAD  0    \n",
            "65508  Always I’ve existed in a state of love. I know of no other way. It’d be an alien tongue, even if I tried to claim it.     0    \n",
            "42246  @USER @USER Thank you and Nancy but Trump doesn't read and will do nothing.                                               0    \n",
            "14712  Blink 182 at the Forum ☺️                                                                                                 0    \n",
            "90625  @USER Why lower the flag to begin with if he's such a racist? Utter stupidity                                             1    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwzFVj6KT37",
        "colab_type": "code",
        "outputId": "5533a992-4449-4890-c73e-4baa32df93ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "data_df.split.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    63622\n",
              "test     13635\n",
              "val      13633\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g10Czw0KJth",
        "colab_type": "code",
        "outputId": "6c64ab1d-de4f-4561-985a-a18f60fb78ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "len(data_df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90890"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKy-82YrG2hh",
        "colab_type": "text"
      },
      "source": [
        "## Create the text preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyhSisD5G2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPT2Preprocessor:\n",
        "    def __init__(self, transformer_tokenizer, sentence_detector):\n",
        "        self.transformer_tokenizer = transformer_tokenizer\n",
        "        self.sentence_detector = sentence_detector\n",
        "\n",
        "    def add_eos_tokens(self, text):\n",
        "        eos_token = \" \" + self.transformer_tokenizer.eos_token + \" \"\n",
        "        sentences = self.sentence_detector.tokenize(text)\n",
        "        eos_added_text = (\n",
        "            eos_token.join(sentences) + \" \" + self.transformer_tokenizer.eos_token\n",
        "        )\n",
        "        return eos_added_text\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCMVmYNJHca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "d9f9a9ca-746c-4618-e723-195c4ac86819"
      },
      "source": [
        "!python -c 'import nltk; nltk.download(\"punkt\")'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "uX6GH1WNG2hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "f533325742ee439f82d76759601e356b",
            "d7e532fc04c54e908d7b41515b6afb2f",
            "3f52138325ef40bc9fac416f7ef6d0d9",
            "560f0a54a4ea45478d9d1ca4cb1913df",
            "2aa1db5679574fc6a5d9fa2fc5ad598b",
            "d49d1c01c55040638c3c7f366112e53a",
            "07976c96504b4bbaa5ec94507c802d42",
            "276186fd61a74c0ba0bf19acd8a35853",
            "e53386b0787747909e88880b2ce6ce66",
            "b63ee51c9e834a5da6a29d36cf0fca25",
            "3b81cb6c0f514536830dd6c71fbf4a6e",
            "b6524ac1b64040428594f8ed6e7af963",
            "5e6bd4cb2f51465eb7c5865499e78a24",
            "780fb3de7b4743c58c58a6ecd8838d07",
            "f35652ef578448b8beb232f0bb96256b",
            "86d49be9ca694186b3f775a371ed100c"
          ]
        },
        "outputId": "8608b63b-0d3e-4437-e53f-6a8d8828e435"
      },
      "source": [
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140245049182248 acquired on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpaz5osfz5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f533325742ee439f82d76759601e356b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=1042301, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json in cache at /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:filelock:Lock 140245049182248 released on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140245049182248 acquired on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_onaooj3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e53386b0787747909e88880b2ce6ce66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt in cache at /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "INFO:filelock:Lock 140245049182248 released on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-vocab.json from cache at /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-merges.txt from cache at /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XZCJQllG2hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2_preproc = GPT2Preprocessor(gpt2_tokenizer, punkt_sentence_detector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U32yNFVz9co_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "abed6d6b-4ea2-450a-8521-e42213bf3f68"
      },
      "source": [
        "data_df['text']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        @USER dancing is a talent show it offffff like...\n",
              "1        Cooking Tweeps!  I am desirous of a new ridged...\n",
              "2        @USER I can respect that I’ll see I kind of li...\n",
              "3        That song used to bring tears to my eyes in 5t...\n",
              "4        Nah.  Ranked. 1. Abortion 2. Guns 3.  Religiou...\n",
              "                               ...                        \n",
              "90885     This bitch wants people to die in a Mass Murder!\n",
              "90886    rly feel like the ugliest girl in the world im...\n",
              "90887    @USER I have the ss and was defending her cuz ...\n",
              "90888    I THOUGHT SHE WAS PREGNANT BUT THAT WAS HER AS...\n",
              "90889    @USER Who the hell are you?Have you forgotten ...\n",
              "Name: text, Length: 90890, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4JACIdi9bWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add the special tokens\n",
        "data_df[\"text\"] = data_df[\"text\"].map(gpt2_preproc.add_eos_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43q7GSYEG2hu",
        "colab_type": "text"
      },
      "source": [
        "### Create the torch torch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlI6CoLfG2hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = transformer_data_utils.HateDataset(\n",
        "        data_df=data_df, tokenizer=gpt2_tokenizer\n",
        "    )\n",
        "assert dataset._max_seq_length <= 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0izVXm7xG2h2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last,\n",
        "                            pin_memory= pinned_memory,\n",
        "                            num_workers = n_workers,\n",
        "                            )\n",
        "    \n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        out_data_dict['x_data'] = data_dict['x_data'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_attn_mask'] = data_dict['x_attn_mask'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_index'] = data_dict['x_index']\n",
        "        out_data_dict['y_target'] = data_dict['y_target'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        yield out_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZsYMvrI_da7",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYFlt6Au_F1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleGPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        hidden_size: int,\n",
        "        num_classes:int ,\n",
        "        max_seq_len:int,\n",
        "        gpt_model_name:str, \n",
        "    ):\n",
        "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(\n",
        "            gpt_model_name\n",
        "        )\n",
        "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x_in):\n",
        "        \n",
        "        gpt_out = self.gpt2model(x_in)[0] #returns tuple\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        prediction_vector = self.fc1(gpt_out.view(batch_size,-1)) #(batch_size , max_len, num_classes)\n",
        "    \n",
        "        return prediction_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4MGsBSm_oXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924,
          "referenced_widgets": [
            "c36900265d1e48d2b55533b7925ed181",
            "491bd6da924c4b83a20c69791ecccf9c",
            "21e6171efeac4f47a7d0d55b371f369e",
            "9d0c545167ad49ad9e924607062fc107",
            "5902425515e84a4c8ee061f370c3cbf0",
            "07e317fcd8b0402a9d457eaa1f904e0e",
            "99538b23a3a8406e83a26648441c5df6",
            "5e3569d57a8445dd8403e5ffb694a607",
            "80a2b725f56e43cda97d34c78caf291c",
            "0dd9f8a227d44acf8094aebcbed274ee",
            "b1640898470b4a4096977d7aa1443c9f",
            "d747855572f745749eb9509faaf844fd",
            "e88ca84c65b9496d940fe679899507b5",
            "60741d631e784394b1b5a0f9d4959325",
            "115c0887e5b744f4ba77808ab646baf3",
            "42c3babaf5d94a4db582e2f860d54300"
          ]
        },
        "outputId": "371196a0-de78-4201-b2d4-811d348024c0"
      },
      "source": [
        "print(\"Loading Pretrained distilgpt2...\")\n",
        "num_classes = len(set(data_df.label))\n",
        "hidden_size = dataset._max_seq_length * 768\n",
        "model = SimpleGPT2SequenceClassifier(\n",
        "    hidden_size=hidden_size,\n",
        "    num_classes=num_classes,\n",
        "    gpt_model_name=\"distilgpt2\",\n",
        "    max_seq_len=dataset._max_seq_length,\n",
        ")\n",
        "print(\"Finished\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Pretrained distilgpt2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140241796885528 acquired on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.a8b35e282ef6b386ae29500ff942def3dd5a8bf71de78a3d36221d6d90031bb5.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5u41klsm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c36900265d1e48d2b55533b7925ed181",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=651, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json in cache at /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.a8b35e282ef6b386ae29500ff942def3dd5a8bf71de78a3d36221d6d90031bb5\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.a8b35e282ef6b386ae29500ff942def3dd5a8bf71de78a3d36221d6d90031bb5\n",
            "INFO:filelock:Lock 140241796885528 released on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.a8b35e282ef6b386ae29500ff942def3dd5a8bf71de78a3d36221d6d90031bb5.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-config.json from cache at /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.a8b35e282ef6b386ae29500ff942def3dd5a8bf71de78a3d36221d6d90031bb5\n",
            "INFO:transformers.configuration_utils:Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140241796885136 acquired on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "INFO:transformers.file_utils:https://cdn.huggingface.co/distilgpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp0g9a_e4a\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80a2b725f56e43cda97d34c78caf291c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=352833716, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://cdn.huggingface.co/distilgpt2-pytorch_model.bin in cache at /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n",
            "INFO:filelock:Lock 140241796885136 released on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/distilgpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:Weights of GPT2Model not initialized from pretrained model: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AvKmZUh_G2iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLAYZmmtG2iJ",
        "colab_type": "text"
      },
      "source": [
        "# Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtX_A6l0Aq6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "98f9505f-0acb-48c5-ee23-1b16e799da51"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "base_optimizer = RAdam(model.parameters(), lr=args.learning_rate)\n",
        "optimizer = Lookahead(optimizer=base_optimizer, k=5, alpha=0.5)\n",
        "print(f\"Using LR:{args.learning_rate}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using LR:0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vC3ewUSnG2iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_state = general_utils.make_train_state()\n",
        "train_state[\"ckpt\"] = 0\n",
        "train_state['max_seq_len'] = dataset._max_seq_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr0zwdnYKNtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6dd14dae-1495-4255-8b13-d0c9e213c2af"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May  4 04:47:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   27C    P8     6W /  75W |     10MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc81HVEZKWzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args.batch_size = 16 #based on your hardware. 1GB per batch."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qg3U6LcmG2iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_bar = notebook.tqdm(\n",
        "    desc = 'training_routine',\n",
        "    total = args.num_epochs,\n",
        "    position=0,\n",
        "    leave = True,\n",
        ")\n",
        "dataset.set_split('train')\n",
        "train_bar = notebook.tqdm(\n",
        "    desc = 'split=train ',\n",
        "    total=dataset.get_num_batches(args.batch_size),\n",
        "    position=0,\n",
        "    leave=True,\n",
        ")\n",
        "dataset.set_split('val')\n",
        "eval_bar = notebook.tqdm(\n",
        "    desc = 'split=eval',\n",
        "    total=dataset.get_num_batches(args.batch_size),\n",
        "    position=0,\n",
        "    leave=True,\n",
        ")\n",
        "\n",
        "for epoch_index in range(args.num_epochs):\n",
        "    train_state['epoch_in'] = epoch_index\n",
        "\n",
        "    dataset.set_split('train')\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = True, n_workers = 3, \n",
        "    )\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    running_f1 = 0.0\n",
        "    model.train()\n",
        "\n",
        "    train_bar.reset(\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "    model.train()\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(\n",
        "            input_ids = batch_dict['x_data'],\n",
        "            attention_mask =  batch_dict['x_attn_mask'],\n",
        "        )\n",
        "        y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
        "                             \n",
        "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                             \n",
        "        loss_t = loss.item()\n",
        "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "                             \n",
        "        y_pred = y_pred.detach().cpu()\n",
        "        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
        "        \n",
        "        acc_t = transformer_general_utils \\\n",
        "            .compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "\n",
        "        f1_t = transformer_general_utils \\\n",
        "            .compute_macro_f1(y_pred, batch_dict['y_target'], average='weighted')\n",
        "\n",
        "        train_state['batch_preds'].append(y_pred)\n",
        "        train_state['batch_targets'].append(batch_dict['y_target'])\n",
        "        train_state['batch_indexes'].append(batch_dict['x_index'])\n",
        "\n",
        "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
        "\n",
        "        train_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
        "                             epoch=epoch_index)\n",
        "\n",
        "        train_bar.update()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    train_state['train_accuracies'].append(running_acc)\n",
        "    train_state['train_losses'].append(running_loss)\n",
        "    \n",
        "    train_state['train_preds'].append(\n",
        "        torch.cat(train_state['batch_preds']).cpu()\n",
        "    )\n",
        "    train_state['train_targets'].append(\n",
        "        torch.cat(train_state['batch_targets']).cpu()\n",
        "    )\n",
        "    train_state['train_indexes'].append(\n",
        "        torch.cat(train_state['batch_indexes']).cpu()\n",
        "    )\n",
        "    train_f1 = transformer_general_utils \\\n",
        "                .compute_macro_f1(train_state['train_preds'][-1],\n",
        "                                  train_state['train_targets'][-1],\n",
        "                                  'weighted'\n",
        "                                 )\n",
        "                                 \n",
        "    train_state['train_f1s'].append(train_f1)\n",
        "    \n",
        "    train_state['batch_preds'] = []\n",
        "    train_state['batch_targets'] = []\n",
        "    train_state['batch_indexes'] = []\n",
        "    \n",
        "    \n",
        "    dataset.set_split('val')\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = False, n_workers = 2, \n",
        "    )\n",
        "    eval_bar.reset(\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    running_f1 = 0.0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        optimizer._backup_and_load_cache()\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            y_pred = model(\n",
        "                input_ids = batch_dict['x_data'],\n",
        "                attention_mask =  batch_dict['x_attn_mask'],\n",
        "            )\n",
        "            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
        "\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            y_pred = y_pred.detach()\n",
        "            \n",
        "            acc_t = transformer_general_utils\\\n",
        "                .compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            f1_t = transformer_general_utils \\\n",
        "                .compute_macro_f1(y_pred, batch_dict['y_target'],\n",
        "                                 average='weighted')\n",
        "\n",
        "            train_state['batch_preds'].append(y_pred.cpu())\n",
        "            train_state['batch_targets'].append(batch_dict['y_target'])\n",
        "            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
        "\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
        "            \n",
        "\n",
        "            eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
        "                                 epoch=epoch_index)\n",
        "            eval_bar.update()\n",
        "            \n",
        "    train_state['val_accuracies'].append(running_acc)\n",
        "    train_state['val_losses'].append(running_loss)\n",
        "    \n",
        "        \n",
        "    train_state['val_preds'].append(\n",
        "        torch.cat(train_state['batch_preds']).cpu()\n",
        "    )\n",
        "\n",
        "    train_state['val_targets'].append(\n",
        "        torch.cat(train_state['batch_targets']).cpu()\n",
        "    )\n",
        "    train_state['val_indexes'].append(\n",
        "        torch.cat(train_state['batch_indexes']).cpu()\n",
        "    )\n",
        "    val_f1 = transformer_general_utils \\\n",
        "                .compute_macro_f1(train_state['val_preds'][-1],\n",
        "                                  train_state['val_targets'][-1],\n",
        "                                  average='weighted',\n",
        "                                 )\n",
        "                                 \n",
        "    train_state['val_f1s'].append(val_f1)\n",
        "    \n",
        "    train_state['batch_preds'] = []\n",
        "    train_state['batch_targets'] = []\n",
        "    train_state['batch_indexes'] = []\n",
        "    \n",
        "    torch.save(\n",
        "        {\n",
        "            'model':model.state_dict(),\n",
        "        },\n",
        "        args.directory + f'_epoc_{epoch_index}_' + args.model_name,\n",
        "    )\n",
        "    \n",
        "    scheduler.step(val_f1)\n",
        "    early_stopping(val_f1, model)\n",
        "    optimizer._clear_and_load_backup()\n",
        "    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1)\n",
        "    epoch_bar.update()    \n",
        "    \n",
        "    if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1 )\n",
        "    epoch_bar.update()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "X3cbb-1dG2iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_state['train_f1s'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYjyEe1G2iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_state['val_f1s'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJePw9boG2iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrQhfw2iG2iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_run_index = train_state['val_f1s'].index(max(train_state['val_f1s']))\n",
        "print(f'Best run at epoch {best_run_index}')\n",
        "print('Train:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['train_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['train_targets'][best_run_index].cpu().numpy(), \n",
        "    digits=4)\n",
        ")\n",
        "print('Dev:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n",
        "    digits=4)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI1XaxsPG2ib",
        "colab_type": "text"
      },
      "source": [
        "## Check if ensembling helps and pick models to use on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOEv36m1G2ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_preds(indexes, preds):\n",
        "    \"\"\"Sorts the predictions in order, to reverse the effects of shuffle\n",
        "    done by dataloader\"\"\"\n",
        "    indexes = indexes.cpu().numpy().reshape(-1,1)\n",
        "    preds = preds.cpu().numpy()\n",
        "    arr_concat = np.hstack((indexes,preds)) #concat the preds and their indexes\n",
        "    sort_arr = arr_concat[ arr_concat[:,0].argsort()] #sort based on the indexes\n",
        "    sorted_preds = np.delete(sort_arr,0,axis=1)\n",
        "    return sorted_preds\n",
        "\n",
        "def get_optimal_models(train_state, split, reverse=False ):\n",
        "    \"\"\"Naive Ensembling\"\"\"\n",
        "    trgts= sort_preds(train_state[f'{split}_indexes'][-1],train_state[f'{split}_targets'][-1].reshape(-1,1))\n",
        "    total_preds = len(train_state[f'{split}_indexes'])\n",
        "    init = np.zeros(train_state[f'{split}_preds'][-1].shape)\n",
        "    max_f1 = 0\n",
        "    idxes = []\n",
        "    rng = range(0,total_preds)\n",
        "    if reverse:\n",
        "        rng = reversed(rng)\n",
        "    for i in rng:\n",
        "        temp = sort_preds(train_state[f'{split}_indexes'][i],train_state[f'{split}_preds'][i])\n",
        "        temp2 = init+temp\n",
        "        f1 = f1_score(\n",
        "            y_pred=temp2.argmax(axis=1),\n",
        "            y_true= trgts, average ='weighted'\n",
        "        )\n",
        "        if f1 > max_f1:\n",
        "            max_f1 = f1\n",
        "            init = init+temp\n",
        "            idxes.append(i)\n",
        "    print(f'Taking preds from {idxes} | Dev f1:{f1}')\n",
        "    return (idxes,max_f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDBXq6bCX5P_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_state['val_f1s']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vWIVkH1yG2ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model_f1_score = f1_score(\n",
        "    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n",
        "    average='weighted'\n",
        ")\n",
        "_models= [get_optimal_models(train_state,'val', reverse=False),\n",
        "                 get_optimal_models(train_state,'val', reverse=True),\n",
        "                 ([best_run_index],best_model_f1_score),]\n",
        "optimal_models = max(_models, key=lambda x:x[1]) #select ensembles or best model \n",
        "print(f'Optimal models chosen: {optimal_models}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l8TL72xSG2ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {args.directory}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpjIrLT7G2ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_models= [os.path.join(args.directory,i) for i in os.listdir(args.directory) if args.model_name in i]\n",
        "all_models = sorted(all_models, key = lambda x: int(x[8])) #sort by epoch num.\n",
        "all_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fya481n6G2im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_models = [all_models[i] for i in optimal_models[0]]\n",
        "pprint.pprint(selected_models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLdc2BW3G2iq",
        "colab_type": "text"
      },
      "source": [
        "## Loading test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZx05lCxG2ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_loc = '/content/trac2020_submission/data/test/trac2_hin_test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN8JtlJNG2it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(test_set_loc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96k6QhTcG2iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['text'] = test_df['Text'].map(roberta_preproc.add_special_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeXnNh0G2ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['split'] = 'test'  #dummy label\n",
        "test_df['label'] = -1  #dummy label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p4nzTM8G2iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DanekyzcG2i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = TracDataset(\n",
        "    data_df = test_df,\n",
        "    tokenizer = xlmroberta_tokenizer,\n",
        "    max_seq_length = dataset._max_seq_length\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DoISn3hG2i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset.set_split('test')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqOKf2fG2i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset._target_df.split.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5AQRrWaG2i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_state = general_utils.make_train_state() \n",
        "test_dataset.set_split('test')\n",
        "eval_bar = notebook.tqdm(\n",
        "    desc = 'split=train ',\n",
        "    total=test_dataset.get_num_batches(args.batch_size),\n",
        "    position=0,\n",
        "    leave=True,\n",
        ")\n",
        "model.eval()\n",
        "for m in notebook.tqdm(selected_models, total=len(selected_models)):\n",
        "    eval_bar.reset(\n",
        "        total=test_dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "    model.load_state_dict(torch.load(m)['model'])\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= test_dataset, batch_size= args.batch_size, shuffle=False,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = True, n_workers = 1, \n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            y_pred = model(\n",
        "                input_ids = batch_dict['x_data'],\n",
        "                attention_mask =  batch_dict['x_attn_mask'],\n",
        "            )\n",
        "            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
        "            \n",
        "            y_pred = y_pred.detach()\n",
        "            \n",
        "            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
        "            test_state['batch_preds'].append(y_pred.cpu())\n",
        "            test_state['batch_targets'].append(batch_dict['y_target'].cpu())\n",
        "            test_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
        "            eval_bar.update()\n",
        "\n",
        "    test_state['val_preds'].append(\n",
        "        torch.cat(test_state['batch_preds']).cpu()\n",
        "    )\n",
        "    test_state['val_targets'].append(\n",
        "        torch.cat(test_state['batch_targets']).cpu()\n",
        "    )\n",
        "    test_state['val_indexes'].append(\n",
        "        torch.cat(test_state['batch_indexes']).cpu()\n",
        "    )\n",
        "    \n",
        "    test_state['batch_preds'] = []\n",
        "    test_state['batch_targets'] = []\n",
        "    test_state['batch_indexes'] = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBLNs164G2i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(test_state['val_preds']) == len(optimal_models[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tPSiWo8bjPR",
        "colab_type": "text"
      },
      "source": [
        "### Add the last layer outputs and apply argmax "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiiCZ-VyG2i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble = torch.zeros_like(test_state['val_preds'][-1])\n",
        "for i in test_state['val_preds']:\n",
        "    ensemble += i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqINUy7gG2jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = torch.argmax(ensemble, dim=1).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fctK1svvG2jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collections.Counter(test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrwD7ZE_G2jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# task_b_label_dict = {'NGEN':0, 'GEN':1} #ref Reading TRAC2020 data... ipynb\n",
        "int_to_label = {0:'NGEN', 1:'GEN'}\n",
        "pred_labels = [int_to_label[i] for i in test_preds]\n",
        "collections.Counter(pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJahLYRG2jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame( data= {'id':test_df.ID, 'label':pred_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyQiODTBG2jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_analysis_df = pd.DataFrame( data= {'id':test_df.ID, 'text':test_df.Text ,'label':pred_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1C3S0zUDG2jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ2RV3NWG2jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_analysis_df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}